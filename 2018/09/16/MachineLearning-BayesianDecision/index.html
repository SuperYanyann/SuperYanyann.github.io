<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="DataMining,MachineLearning,">










<meta name="description" content="概述&amp;emsp;&amp;emsp;贝叶斯决策理论是机器学习中一个比较重要的组成部分，贝叶斯学派的思想对于机器学习的影响也比较深远。之间根据西瓜书学习过一些贝叶斯决策理论相关的知识，并写过一个简单的程序。这个对于其理论方法做进一步的学习。主要参考张学工的《模式识别(第三版)》。 基本概念三个概率&amp;emsp;&amp;emsp;首先熟悉下贝叶斯决策的三个概率：&amp;emsp;&amp;emsp;先验概率：从以往的数据分析中得到">
<meta name="keywords" content="DataMining,MachineLearning">
<meta property="og:type" content="article">
<meta property="og:title" content="MachineLearning-BayesianDecision">
<meta property="og:url" content="http://yoursite.com/2018/09/16/MachineLearning-BayesianDecision/index.html">
<meta property="og:site_name" content="SuperYanyann&#39;s World">
<meta property="og:description" content="概述&amp;emsp;&amp;emsp;贝叶斯决策理论是机器学习中一个比较重要的组成部分，贝叶斯学派的思想对于机器学习的影响也比较深远。之间根据西瓜书学习过一些贝叶斯决策理论相关的知识，并写过一个简单的程序。这个对于其理论方法做进一步的学习。主要参考张学工的《模式识别(第三版)》。 基本概念三个概率&amp;emsp;&amp;emsp;首先熟悉下贝叶斯决策的三个概率：&amp;emsp;&amp;emsp;先验概率：从以往的数据分析中得到">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-09-16T16:24:56.271Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MachineLearning-BayesianDecision">
<meta name="twitter:description" content="概述&amp;emsp;&amp;emsp;贝叶斯决策理论是机器学习中一个比较重要的组成部分，贝叶斯学派的思想对于机器学习的影响也比较深远。之间根据西瓜书学习过一些贝叶斯决策理论相关的知识，并写过一个简单的程序。这个对于其理论方法做进一步的学习。主要参考张学工的《模式识别(第三版)》。 基本概念三个概率&amp;emsp;&amp;emsp;首先熟悉下贝叶斯决策的三个概率：&amp;emsp;&amp;emsp;先验概率：从以往的数据分析中得到">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/09/16/MachineLearning-BayesianDecision/">





  <title>MachineLearning-BayesianDecision | SuperYanyann's World</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SuperYanyann's World</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Don't cry because it is over,smile because it happened</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/09/16/MachineLearning-BayesianDecision/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Wang">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/../images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SuperYanyann's World">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MachineLearning-BayesianDecision</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-16T23:12:58+08:00">
                2018-09-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>&emsp;&emsp;贝叶斯决策理论是机器学习中一个比较重要的组成部分，贝叶斯学派的思想对于机器学习的影响也比较深远。之间根据西瓜书学习过一些贝叶斯决策理论相关的知识，并写过一个简单的程序。这个对于其理论方法做进一步的学习。主要参考张学工的《模式识别(第三版)》。</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="三个概率"><a href="#三个概率" class="headerlink" title="三个概率"></a>三个概率</h2><p>&emsp;&emsp;首先熟悉下贝叶斯决策的三个概率：<br>&emsp;&emsp;<strong>先验概率</strong>：从以往的数据分析中得到的经验值;即根据大量统计确定某类事物出现的比例。<br>&emsp;&emsp;<strong>类条件概率密度函数</strong>:同一类事物的各个属性都有一定的变化范围,在这些变化范围内的分布概率用一种函数形式表示,则称为类条件概率密度函数。(这种分<br>布密度只对同一类事物而言,与其它类事物没有关系。为了强调是同一类事物内部,因此这种分布密度函数往往表示成条件概率的形式。)<br>&emsp;&emsp;<strong>后验概率</strong>:得到信息之后,对以往数据加以修正的概率(一般也是条件概率);或一个具体事物属于某种类别的概率。需要注意的是，后验概率与先验概率也不同,后验概率涉及一个具体事物,而先验概率是泛指一类事物。</p>
<h2 id="判定函数"><a href="#判定函数" class="headerlink" title="判定函数"></a>判定函数</h2><p>&emsp;&emsp;对于判定函数的概念可以不要理解的那么死板，它可以是针对某一个判定的类别而言的，也可以是前者之间的差。此处我们假设为简单的二分类问题，并以差的形式进行描述，有一下四种常用的形式：<br>&emsp;&emsp;<strong>后验概率形式</strong>：$ g(x) = P(\omega _1 | x) - P(\omega _2 |x) $<br>&emsp;&emsp;<strong>类条件概率密度形式</strong>： $ g(x) = P(x | \omega _1)P(\omega _1) - P(x | \omega _2)P(\omega _2) $<br>&emsp;&emsp;<strong>似然比形式</strong>： $ g(x) = \frac{P(x | \omega_1)}{ P(x | \omega _2) } - \frac{P(\omega _2)}{P(\omega _1)} $<br>&emsp;&emsp;<strong>取对数形式</strong>： $ g(x) = ln \frac{P(x | \omega _1)}{P(x | \omega _2)} - ln \frac{P(\omega _2)}{ P(\omega _1)} $<br>&emsp;&emsp;决策规则实际上就是根据样本判定函数的结果大小来判断样本所属的类型，如果判定函数是$g_i(x)$的话，则计算出使其最大的类别作为样本的类别。如果是差的形式的话，就根据其与0的大小关系判断，有时也会根据需要进行加权。例如最小错误率贝叶斯决策规则和最小风险贝叶斯决策规则。<br>&emsp;&emsp;决策面则可以根据$g_i(x) = g_j(x) (i \neq j)$这类决策函数的相等关系来计算得到。</p>
<h2 id="正态分布"><a href="#正态分布" class="headerlink" title="正态分布"></a>正态分布</h2><p>&emsp;&emsp;之后会重点分析类条件概率密度函数服从正态分布的贝叶斯决策方法，其原因是正态分布满足物理上的合理性，以及数学上的简单性。所以此处对于正态分布基础概念做一个简单的回顾。<br>&emsp;&emsp;单变量正态分布的概率密度函数为：<br>$$ p(x) = \frac{1}{\sqrt{2 \pi} \sigma} exp \bigg{  -\frac{1}{2} ( \frac{x - \mu}{ \sigma } )^2 \bigg}$$<br>&emsp;&emsp;多变量正态分布的概率密度函数为：<br>$$ p(\overrightarrow{x}) = \frac{1}{ (2 \pi)^{n/2} | \mathbf{\Sigma}|^{1/2}} exp \bigg{  -\frac{1}{2}  (\overrightarrow{x} - \overrightarrow{\mu})^T \Sigma ^{-1} (\overrightarrow{x} - \overrightarrow{\mu}) \bigg}  $$<br>&emsp;&emsp;其中均值向量和协方差矩阵的计算如下：<br>$$ \overrightarrow{\mu} = E{ { \overrightarrow{x} }} \<br>\mathbf{\Sigma} = E { (\overrightarrow{x} - \overrightarrow{\mu})(\overrightarrow{x} - \overrightarrow{\mu})^T } $$<br>&emsp;&emsp;多元正态分布的性质列举如下：</p>
<ul>
<li>参数 $\overrightarrow{\mu}$ 和参数 $ \mathbf{\Sigma} 对于正太分布的决定性</li>
<li>等密度点的轨迹为一超椭球面</li>
<li>不相关性等价与独立性</li>
<li>边缘分布和条件分布的正态性</li>
<li>线性变化的正态性</li>
<li>线性组合的正态性</li>
</ul>
<p>&emsp;&emsp;关于性质详细的说明和推导可以参考《模式识别(第三版)》。</p>
<h1 id="最小错误率贝叶斯和最小风险贝叶斯"><a href="#最小错误率贝叶斯和最小风险贝叶斯" class="headerlink" title="最小错误率贝叶斯和最小风险贝叶斯"></a>最小错误率贝叶斯和最小风险贝叶斯</h1><h2 id="最小错误率贝叶斯决策"><a href="#最小错误率贝叶斯决策" class="headerlink" title="最小错误率贝叶斯决策"></a>最小错误率贝叶斯决策</h2><p>&emsp;&emsp;最小错误率贝叶斯决策，顾名思义就是使得分类的错误率最小的决策规则。我们的目标是最小化错误率公式，即：<br>$$ minP(e) = \int P(e | x)p(x)dx $$<br>&emsp;&emsp;对于两类分类问题，利用其后验概率，有如下规则:<br>$$ 如果 P(\omega <em>1 | x) &gt; P(\omega _2 |x), 则 x \in \omega _1 ; 反之 x \in \omega _2   $$<br>&emsp;&emsp;对于多类分类的情况，有如下规则：<br>$$  若 P(\omega _i | \overrightarrow{x}) = \max</em>{j = 1,…n} P(\omega <em>j |\overrightarrow{x}),则 \overrightarrow{x} \in \omega _i $$<br>&emsp;&emsp;另外的，针对两类问题，我们可以得到将第一类样本错分为第二类的错误率$P_1(e)$和将第二类样本错分为第一类的错误率$P_2(e)$为：<br>$$ P_1(e) = \int</em>{R_2} p(x | \omega <em>1) dx  \<br>P_2(e) = \int</em>{R_1} p(x | \omega _2) dx $$</p>
<h2 id="最小风险贝叶斯决策"><a href="#最小风险贝叶斯决策" class="headerlink" title="最小风险贝叶斯决策"></a>最小风险贝叶斯决策</h2><p>&emsp;&emsp;基于最小错误率决策的方法无法估计做出错误决策所带来的损失，例如在一次对于患者诊断中，我们清楚的理解将患病的人诊断为未患病的人比将未患病的人诊断为患病后果严重的多。因此我们可以将最小风险贝叶斯决策理解为最小错误率贝叶斯的加权，当其每个错误的权值相同时，最小风险贝叶斯就等同于最小错误率贝叶斯。<br>&emsp;&emsp;我们需要先熟悉以下概念：<br>&emsp;&emsp;决策$\alpha <em>i$：将需判定的样本判定为$\omega _i$类<br>&emsp;&emsp;损失函数$\lambda (\alpha _i , \omega _j)$：对于实际为第$\omega _j$类样本，采取决策$\alpha _i$所带来的损失<br>&emsp;&emsp;一般决策表：对于每个状态$\omega _j$对应的每个$\alpha _j $的损失函数$\lambda (\alpha _i , \omega _j)$的表格<br>&emsp;&emsp;由此我们可以得出对于某个样本采取决策$\alpha _i$的期望损失(条件风险)为：<br>$$ P(\alpha _i | \overrightarrow{x}) = \sum\limits^{n}</em>{j=1} \lambda (\alpha <em>i , \omega _j) P(\omega _j | \overrightarrow{x}) $$<br>&emsp;&emsp;决策$\alpha (x)$对于空间中所有可能的样本采取决策所造成的期望损失为：<br>$$ R(\alpha) = \int R(\alpha(\overrightarrow{x}) | \overrightarrow{x})p(\overrightarrow{x})d \overrightarrow{x} $$<br>&emsp;&emsp;所以我们可以得到需要最小化的公式为：<br>$$ \min</em>{\alpha} R(\alpha)$$<br>&emsp;&emsp;由此我们得到最小风险贝叶斯决策为；<br>$$ \alpha = arg \min_{i=1,…,k}R(\alpha _i | \overrightarrow{x}) $$<br>&emsp;&emsp;由此我们也可以看出，最小错误率贝叶斯决策实质上是最小风险贝叶斯的一种特殊形式。</p>
<h1 id="Neyman-Pearson决策"><a href="#Neyman-Pearson决策" class="headerlink" title="Neyman-Pearson决策"></a>Neyman-Pearson决策</h1><p>&emsp;&emsp;Neyman-Pearson决策是指在决策的过程中，限定一类错误率为常数而使另一类错误率最小的决策规则。要求描述如下：<br>\begin{equation<em>}<br>\begin{split}<br>{ min}\quad &amp;P_1(e)\<br>{ s.t.}\quad &amp;P_2(e) - \varepsilon _0 = 0\<br>\end{split}<br>\end{equation</em>}</p>
<p>&emsp;&emsp;利用Lagrange乘子法把有约束的极值问题转换为：<br>$$ min \gamma = P_1(e) + \lambda(P_2(e) - \varepsilon <em>0) $$<br>&emsp;&emsp;需要说明的是$\gamma$为Lagrange算子，R为整个特征空间，$R_1+ R_2 = R$,两个决策区域之间的边界为$t$,考虑概率密度函数的性质，可以将上式化简为：<br>$$ \gamma = \int</em>{R_2}p(x | \omega_1)dx + \lambda[\int <em>{R_1} p(x | \omega _2)dx - \varepsilon _0] \<br>\gamma = (1 - \lambda \varepsilon _0) + \int</em>{R_1} [\lambda p(x | \omega <em>2) - p(x | \omega _1)] dx $$<br>&emsp;&emsp;优化的目标是求解使其最小的决策边界t，将上式分别对$\lambda$和$t$求导，利用极值点导数为0可以得到$t$应该满足：<br>$$ \int</em>{R_1} p(x | \omega _2)dx = \varepsilon _0 $$<br>&emsp;&emsp;$\lambda$应该满足<br>$$ \lambda = \frac{p(x | \omega _1)}{ p(x | \omega _2)} $$<br>&emsp;&emsp;可以得到决策规则为：<br>$$ p(x | \omega _1) &gt; \lambda p(x | \omega _2) 则x \in \omega _1,否则 x \in \omega _2$$<br>&emsp;&emsp;其中$\lambda$是使决策区域满足条件的一个阈值，而$\lambda$很难求得封闭解，因此用似然比密度函数来确定。</p>
<h1 id="正态分布模型下最小错误率贝叶斯"><a href="#正态分布模型下最小错误率贝叶斯" class="headerlink" title="正态分布模型下最小错误率贝叶斯"></a>正态分布模型下最小错误率贝叶斯</h1><h2 id="基础模型"><a href="#基础模型" class="headerlink" title="基础模型"></a>基础模型</h2><p>&emsp;&emsp;本小结对公式做如下约束：公式中出现的$x$和$\mu$均为向量。<br>&emsp;&emsp;在多元正太分布模型$p(x | \omega_i) \sim N(\mu <em>i,\Sigma)$下，根据取对数形式可以得到判别函数为：<br>$$ g_i(x) = -\frac{1}{2}(x - \mu _i)^T \Sigma^{-1}</em>{i}(x - \mu _i) - \frac{n}{2}ln2\pi - \frac{1}{2}ln|\Sigma_i| + lnP(\omega _i)$$<br>&emsp;&emsp;我们对于基本情况下的协方差和先验概率做约束以简化判别函数。</p>
<h2 id="第一类情况"><a href="#第一类情况" class="headerlink" title="第一类情况"></a>第一类情况</h2><p>&emsp;&emsp;第一类情况为协方差矩阵矩阵相等，并且类内各特征间相互独立，具有相等的方差，即$ \Sigma _i = \sigma ^2 I,i = 1,2…n $<br>&emsp;&emsp;此时当先验概率不相等时，判别函数可以化简为：<br>$$ g_i(x) = -\frac{1}{2 \sigma ^2}(x - \mu _i)^T(x- \mu _i) + lnP(\omega _i) $$<br>&emsp;&emsp;当先验概率相等时，有：<br>$$ g_i(x) = w^T_i x + \omega _{i0} \<br>w_i = \frac{1}{\sigma ^2} \mu _i \<br>\omega _{i0} = \frac{1}{2 \sigma ^2} \mu_i^T \mu_i + lnP(\omega _i) $$</p>
<h2 id="第二类情况"><a href="#第二类情况" class="headerlink" title="第二类情况"></a>第二类情况</h2><p>&emsp;&emsp;第二类情况为各类的协方差矩阵相等时，即$ \Sigma <em>i = \Sigma $。此时判别函数可以简化为：<br>$$ g_i(x) = -\frac{1}{2}(x - \mu _i)^T \Sigma^{-1}</em>{i}(x - \mu <em>i) + lnP(\omega _i)$$<br>&emsp;&emsp;将上式展开，忽略无关项，可将判别式写为：<br>$$ g_i(x) = w^T_i x + \omega _{i0} \<br>w_i = \Sigma^{-1} \mu _i \<br>\omega _{i0} = - \frac{1}{2} \mu_i^T \Sigma^{-1} \mu_i + lnP(\omega _i) $$<br>&emsp;&emsp;若先验概率相等，可以进一步简化为：<br>$$ g_i(x) = (x - \mu _i)^T \Sigma^{-1}</em>{i}(x - \mu _i) $$</p>
<h2 id="第三类情况"><a href="#第三类情况" class="headerlink" title="第三类情况"></a>第三类情况</h2><p>&emsp;&emsp;第三类情况即为多元正态分布的一般情况，这种情况直接从基础模型中删去无关项即可：<br>$$ g_i(x) = -\frac{1}{2}(x - \mu <em>i)^T \Sigma^{-1}</em>{i}(x - \mu <em>i)  - \frac{1}{2}ln|\Sigma_i| + lnP(\omega _i)$$<br>&emsp;&emsp;可以表示为：<br>$$ g_i(x) = x^T W_i x + w_i^T x + w</em>{i0} \<br>W_i = -\frac{1}{2} \Sigma^{-1}<em>i \<br>w_i = \Sigma^{-1}_i \mu_i \<br>w</em>{i0} = - \frac{1}{2} \mu_i^T \Sigma^{-1}_i \mu_i - \frac{1}{2} ln|\Sigma _i| + lnP(\omega _i)$$</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>&emsp;&emsp;本文是关于模式识别中贝叶斯决策主要内容的一个总结，部分内容未写入，如最大最小判别准则、序贯分类等内容。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[1] 张学工，模式识别(第三版)</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/DataMining/" rel="tag"># DataMining</a>
          
            <a href="/tags/MachineLearning/" rel="tag"># MachineLearning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/09/14/MachineLearning-CART-XGboost/" rel="next" title="MachineLearning-CART&XGboost">
                <i class="fa fa-chevron-left"></i> MachineLearning-CART&XGboost
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/09/23/Project-LocatingYellowMark/" rel="prev" title="Project-LocatingYellowMark">
                Project-LocatingYellowMark <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/../images/avatar.jpg" alt="Yan Wang">
            
              <p class="site-author-name" itemprop="name">Yan Wang</p>
              <p class="site-description motion-element" itemprop="description">progressive</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">52</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">27</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#概述"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本概念"><span class="nav-number">2.</span> <span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#三个概率"><span class="nav-number">2.1.</span> <span class="nav-text">三个概率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#判定函数"><span class="nav-number">2.2.</span> <span class="nav-text">判定函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正态分布"><span class="nav-number">2.3.</span> <span class="nav-text">正态分布</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#最小错误率贝叶斯和最小风险贝叶斯"><span class="nav-number">3.</span> <span class="nav-text">最小错误率贝叶斯和最小风险贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#最小错误率贝叶斯决策"><span class="nav-number">3.1.</span> <span class="nav-text">最小错误率贝叶斯决策</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最小风险贝叶斯决策"><span class="nav-number">3.2.</span> <span class="nav-text">最小风险贝叶斯决策</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neyman-Pearson决策"><span class="nav-number">4.</span> <span class="nav-text">Neyman-Pearson决策</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正态分布模型下最小错误率贝叶斯"><span class="nav-number">5.</span> <span class="nav-text">正态分布模型下最小错误率贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基础模型"><span class="nav-number">5.1.</span> <span class="nav-text">基础模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第一类情况"><span class="nav-number">5.2.</span> <span class="nav-text">第一类情况</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第二类情况"><span class="nav-number">5.3.</span> <span class="nav-text">第二类情况</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第三类情况"><span class="nav-number">5.4.</span> <span class="nav-text">第三类情况</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#小结"><span class="nav-number">6.</span> <span class="nav-text">小结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考"><span class="nav-number">7.</span> <span class="nav-text">参考</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yan Wang</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
